{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2b9c0a-8818-4dc9-b734-fad0f70a0170",
   "metadata": {},
   "source": [
    "# Kreuzentropie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37f98d-dcc1-463d-bc44-69f3bf7ff463",
   "metadata": {},
   "source": [
    "Die __Kreuzentropie__ (_Cross-Entropy_) ist eine gängige Verlustfunktion im überwachten Lernen für Klassifikationsprobleme. Sie misst, wie unterschiedlich zwei Wahrscheinlichkeitsverteilungen sind – typischerweise die wahre Verteilung der Klassenlabels und die vorhergesagte Verteilung eines Modells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b4e0b-9eb4-456f-ab4e-84d8a28aa05b",
   "metadata": {},
   "source": [
    "### Mathematische Definition der Kreuzentropie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555876e-7c5d-40f5-9016-310e7e90b48e",
   "metadata": {},
   "source": [
    "Für ein einzelnes Beispiel mit einer Klasse $y$ und einer vorhergesagten Wahrscheinlichkeitsverteilung $\\hat{y}$\n",
    "wird die Kreuzentropie definiert als:\n",
    "\n",
    "$$ \\text{KE}(y,\\hat{y}) := - \\sum_{k=1}^N y_k \\;\\log(\\hat{y_k}) $$\n",
    "\n",
    "Wenn $y$ eine _One-Hot-Kodierung_ ist (nur eine Klasse $k$ hat den Wert 1, alle anderen 0), vereinfacht sich die Formel zu:\n",
    "\n",
    "$$ \\text{KE}(y,\\hat{y}) = -\\log(\\hat{y}_k) $$\n",
    "\n",
    "Für eine gesamte Trainingsmenge mit $m$ Beispielen sieht die mittlere Kreuzentropie so aus:\n",
    "$$ \\text{KE} = -\\frac{1}{m} \\sum_j \\sum_i y_{ji}\\;\\log(\\hat{y}_{ji})   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f1d98-1272-4576-8ed8-06d65cb150c9",
   "metadata": {},
   "source": [
    "### Eigenschaften der Kreuzentropie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f827b-527e-4184-95d9-0d0f76f6428d",
   "metadata": {},
   "source": [
    "* Bestrafung falscher Vorhersagen: Wenn das Modell einer falschen Klasse eine hohe Wahrscheinlichkeit zuweist, wird der Fehler stark bestraft, da $\\log(x)$  für kleine $x$ stark negativ wird.\n",
    "* Anpassung an Wahrscheinlichkeitsverteilungen: Sie ist besonders gut geeignet für Softmax-Ausgaben, da sie Wahrscheinlichkeiten direkt bewertet.\n",
    "* Vermeidung von Ungenauigkeiten bei Gradientenabstiegen: Die Kreuzentropie hat bessere numerische Eigenschaften als z. B. der quadratische Fehler für Klassifikationsprobleme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943856a-2eed-4483-bec4-ff3efdfcc043",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy (BCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2488f9c-4e73-4cdf-80c5-727f5766d3af",
   "metadata": {},
   "source": [
    "Für ein binäres Problem mit einem einzelnen Label $y \\in \\{0,1\\}$ und einer vorhergesagten Wahrscheinlichkeit $\\hat{y}$ vereinfacht sich die Kreuzentropie zu:\n",
    "$$   \\text{KE}(y,\\hat{y}) = - \\sum_{k=1}^N y \\log(\\hat{y}) \\; + \\;(1-y) \\log(1 - \\hat{y}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ffa01-5015-42e3-9cea-ae034ee485e1",
   "metadata": {},
   "source": [
    "### Einsatz der Kreuzentropie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e2c0d-4cde-4dbd-aeb6-af7017a1bbee",
   "metadata": {},
   "source": [
    "Die Kreuzentropie ist eine effektive Verlustfunktion für Klassifikationsprobleme, da sie die Wahrscheinlichkeit für korrekte Vorhersagen maximiert und das Lernen effizienter macht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65cb9e1-4f89-493a-87e7-2a3bb1c7a893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263651a-5bc4-4411-b041-6b20d30d1d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
