{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ece557b-3238-44a2-b87b-705b937ada2c",
   "metadata": {},
   "source": [
    "# Begriffe 3 - Die Verlustfunktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed075f-6662-4e3d-9d7e-c05ff9a67890",
   "metadata": {},
   "source": [
    "Wir haben bei unseren ersten Schritten in der Linearen Regression gesehen, dass sich die Aufgabe zurückführen ließ auf die Minimierung einer Funktion, die zwar sehr viele Parameter haben kann, aber einen einzelnen Zahlenwert liefert. Wir haben dies damals als eine Art Distanz angesehen. In der Künstlichen Intelligenz ist aber der Begriff **Verlustfunktion** (*loss function*) gebräuchlich. Was für ein Verlust? Nun, gehen wir bei der Linearen Regression von dentatsächlich gemessenen Punkten aus zur Gerade über, so verlieren wir auch etwas an Information. Statt der real gemessenen Punkte, die allerdings auch eine sehr große und unhandliche Menge darstellen kann, haben wir nun eine handliche Ausgleichsgerade, mit der wir Punkte abschätzen oder *vorhersagen* können, die gar nicht gemessen wurden. Geht die Ausgleichsgerade hingegen perfekt durch alle drei Punkte, so beträgt die Verlustfunktion exakt Null.\n",
    "\n",
    "Dass wird häufig ein Problem auf die Minimierung einer Funktion zurückführen können, ermöglicht es uns, die bekannten Verfahren aus der Mathematik einsetzen zu können. Wir suchen einfach die Nullstellen der Ableitung, wenn möglich durch direkte Rechnung, ansonsten durch das *Gradientenabstiegsverfahren*. Dieses Verfahren ist universell; das ursprüngliche Problem wird so \"nebenbei\" gelöst, ohne das ein individueller Algorithmus entwickelt werden muss. (Umgekehrt folgt leider, dass die eigentliche Lösung des Problems nicht einfach \"verstanden werden kann\")\n",
    "\n",
    "Die richtige Wahl für die Verlustfunktion ist also entscheidend. Wir stellen hier einige typische Kandidaten vor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c5d7e1-898b-4d7d-b1fe-1196330d4d33",
   "metadata": {},
   "source": [
    "### Regressionsprobleme --> Mittlere Fehlerquadratsumme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abeb97f-65f1-4b68-98be-7bd42766735e",
   "metadata": {},
   "source": [
    "Bei Regressionproblemen geht es darum, ein kontinuierliche Variable vorherzusagen, etwa Temperaturen oder Börsenkurse, und dies auf Basis vorgegebener Werte. Konkret: Sind uns $N$ Wertepaare $(x_1,y_1), \\ldots, (x_N,y_N)$ vorgegeben, wobei die $x_k$ auch mehrere Dimensionen haben dürfen, so suchen wir eine lineare Funktion $F$, die diese Punkte *möglichst genau approximiert*. Wir haben dies dann quantifiziert, in dem wir zu einer gegebenen Funktion $F$ die Abweichungen von den erwartetene Werten $y_k$ quadriert und aufsummiert haben. Dadurch haben wir eine Funktion $\\mathcal{L}$ für $F$ erhalten:\n",
    "\n",
    "$$\\mathcal{L}(F) := \\sum_{k=1}^N (F(x_k) - y_k)^2$$\n",
    "\n",
    "Diese Funktion heißt **Fehlerquadratsumme**. Sie wird für große $N$ natürlich immer größer, und so benutzt man meist die *normierte* Version:\n",
    "\n",
    "$$\\mathcal{L}(F) := \\frac{1}{N} \\sum_{k=1}^N (F(x_k) - y_k)^2.$$\n",
    "\n",
    "In dieser Form wird die Funktion **Mittlere Fehlerquadratsumme** (*Mean Squared Error* - **MSE function**) genannt.\n",
    "\n",
    "Diese Funktion ist optimal für unser Problem:\n",
    "\n",
    "* Sie berücksichtigt alle Punktepaare\n",
    "* Abweichungen gehen immer positiv in die Summe ein\n",
    "* Sie bestraft größere Abstände stärker als kleine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ababc-ca35-4bf9-919e-5e0f7de6d6c5",
   "metadata": {},
   "source": [
    "### Klassifizierungsprobleme ---> Mittlere Kreuzentropie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a3df6-005c-41b6-be42-68a3e8f7d70b",
   "metadata": {},
   "source": [
    "Völlig anderer Natur als Regressionsproblem sind **Klassifizierungsaufgaben**. Hierbei geht es darum, Daten voneinander zu unterscheiden und zu trennen. Dies können Tierfotos sein, wo nach \"Hund\" oder \"Katze\" unterschieden werden muss, oder beim *Iris-Datensatz* die Iris-Sorte nach den Abmessungen der Blätter erkannt werden soll. Hier gibt es mitunter keine klaren Entscheidungen, wenn etwa ein sehr kleiner Hund fast wie eine Katze aussieht, oder man ein besonders großes Exemplar einer sonst kleinen Iris erwischt hat. In diesen Fällen werden nur noch Wahrscheinlichkeitsaussagen getätigt, in der Form \"Dies ist zu 80 % ein Hund, und zu 20 % eine Katze\". Solche Antworten würde ein **Klassifizierer** liefern, den wir suchen.\n",
    "\n",
    "Es ist klar, dass unsere Fehlerquadratsumme uns hier nicht weiterhilft. Stattdessen werden wir bei der Statistik fündig."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
